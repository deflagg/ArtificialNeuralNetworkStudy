{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some notation to make the equations below more readable.  \n",
    "\n",
    "\n",
    "$g=$ activation function of output node (i.e. sigmoid function)  \n",
    "$h_{\\theta}\\left(x\\right)=g\\left(\\theta^{T}x\\right)$  \n",
    "$y_{i}=$ labeled data.  \n",
    "$\\hat{y}=h_{\\theta}\\left(x\\right)$  \n",
    "$C=Cost\\left(\\hat{y},y\\right)$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Cost Function: Regression\n",
    "$C=\\dfrac{1}{2}\\sum\\limits_{i}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy Cost Function: Classification\n",
    "$C=-\\dfrac{1}{m}\\sum\\limits^{m}_{i=1}\\sum\\limits^{K}_{k=1}\\left[y^{(i)}_{k}\\log(\\hat{y}_k)+(1-y^{(i)}_{k})\\log(1-\\hat{y}_{k}) \\right]+\\dfrac{\\lambda}{2m} \\sum\\limits^{L-1}_{l=1}\\sum\\limits^{s_{l}}_{i=1}\\sum\\limits^{s_{l+1}}_{j=1}\\left(\\theta^{(l)}_{j,i}\\right)^{2}$  \n",
    "\n",
    "Note: This is the cost function that is used in the Andrew Ng course in Coursea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Cost Function\n",
    "\n",
    "$C=\\tau\\exp\\left[\\dfrac{1}{\\tau}\\sum\\limits_{i}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hellinger Distance\n",
    "$C=\\dfrac{1}{\\sqrt{2}}\\sum\\limits_{i}\\left(\\sqrt{y_{i}}-\\sqrt{\\hat{y}_{i}}\\right)^{2}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kullback-Leibler Divergence\n",
    "$D_{KL}\\left(P\\|Q\\right) = \\sum\\limits_{j}P\\left(j\\right)\\ln{\\dfrac{P\\left(j\\right)}{Q\\left(j\\right)}}$  \n",
    "\n",
    "$C = \\sum\\limits_{i}y_{i}\\log{\\dfrac{y_{i}}{\\hat{y}_{i}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Kullback-Leibler Divergence\n",
    "$C=\\sum\\limits_{i}y_{i}\\log{\\dfrac{y_{i}}{\\hat{y}_{i}}}-\\sum\\limits_{i}y_{i}-\\sum\\limits_{i}\\hat{y}_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itakura-Saito Distance\n",
    "$C=\\sum\\limits_{i}\\left(\\dfrac{y_{i}}{\\hat{y}_{i}}-\\log{\\dfrac{y_{i}}{\\hat{y}_{i}}}-1\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
